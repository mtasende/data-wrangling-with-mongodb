{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measures of Data Quality\n",
    "\n",
    "- Validity: Conforms to a Schema\n",
    "- Accuracy: Conforms to gold standard\n",
    "- Completeness: All records?\n",
    "- Consistency: Matches other data\n",
    "- Uniformity: Same units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blueprint for Cleaning Data\n",
    "\n",
    "- Audit your Data\n",
    "- Create a Data Cleaning Plan\n",
    "  - Identify causes\n",
    "  - Define operations\n",
    "  - Test\n",
    "- Execute the plan (run a script)\n",
    "- Manually correct\n",
    "\n",
    "\n",
    "Iterate on the process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Your task is to check the \"productionStartYear\" of the DBPedia autos datafile for valid values.\n",
    "The following things should be done:\n",
    "- check if the field \"productionStartYear\" contains a year\n",
    "- check if the year is in range 1886-2014\n",
    "- convert the value of the field to be just a year (not full datetime)\n",
    "- the rest of the fields and values should stay the same\n",
    "- if the value of the field is a valid year in the range as described above,\n",
    "  write that line to the output_good file\n",
    "- if the value of the field is not a valid year as described above, \n",
    "  write that line to the output_bad file\n",
    "- discard rows (neither write to good nor bad) if the URI is not from dbpedia.org\n",
    "- you should use the provided way of reading and writing data (DictReader and DictWriter)\n",
    "  They will take care of dealing with the header.\n",
    "\n",
    "You can write helper functions for checking the data and writing the files, but we will call only the \n",
    "'process_file' with 3 arguments (inputfile, output_good, output_bad).\n",
    "\"\"\"\n",
    "import csv\n",
    "import pprint\n",
    "import datetime as dt\n",
    "\n",
    "INPUT_FILE = 'data/autos.csv'\n",
    "OUTPUT_GOOD = 'data/autos-valid.csv'\n",
    "OUTPUT_BAD = 'data/FIXME-autos.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(date_str):\n",
    "    try:\n",
    "        dt_string = date_str[:-5] + date_str[-5:].replace(':', '')\n",
    "        return dt.datetime.strptime(dt_string, '%Y-%m-%dT%H:%M:%S%z')\n",
    "    except ValueError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_in_range(date):\n",
    "    min_year = 1886\n",
    "    max_year = 2014\n",
    "    return (min_year <= date.year) and (date.year <= max_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "input_file = INPUT_FILE\n",
    "output_good = OUTPUT_GOOD\n",
    "output_bad = OUTPUT_BAD\n",
    "\n",
    "good_data = list()\n",
    "bad_data = list()\n",
    "\n",
    "with open(input_file, \"r\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        header = reader.fieldnames\n",
    "        start_year_idx = header.index('productionStartYear')\n",
    "        for row in reader:\n",
    "            # Check that it is a date\n",
    "            date = get_date(row['productionStartYear'])\n",
    "            if not date:\n",
    "                bad_data.append(row)\n",
    "                continue\n",
    "            # Check the year's range\n",
    "            if not date_in_range(date):\n",
    "                bad_data.append(row)\n",
    "                continue\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['URI',\n",
       " 'rdf-schema#label',\n",
       " 'rdf-schema#comment',\n",
       " 'assembly_label',\n",
       " 'assembly',\n",
       " 'automobilePlatform_label',\n",
       " 'automobilePlatform',\n",
       " 'bodyStyle_label',\n",
       " 'bodyStyle',\n",
       " 'class_label',\n",
       " 'class',\n",
       " 'designCompany_label',\n",
       " 'designCompany',\n",
       " 'designer_label',\n",
       " 'designer',\n",
       " 'engine_label',\n",
       " 'engine',\n",
       " 'fuelCapacity',\n",
       " 'height',\n",
       " 'layout_label',\n",
       " 'layout',\n",
       " 'length',\n",
       " 'manufacturer_label',\n",
       " 'manufacturer',\n",
       " 'modelEndYear',\n",
       " 'modelStartYear',\n",
       " 'parentCompany_label',\n",
       " 'parentCompany',\n",
       " 'predecessor_label',\n",
       " 'predecessor',\n",
       " 'productionEndDate',\n",
       " 'productionEndYear',\n",
       " 'productionStartDate',\n",
       " 'productionStartYear',\n",
       " 'relatedMeanOfTransportation_label',\n",
       " 'relatedMeanOfTransportation',\n",
       " 'sales_label',\n",
       " 'sales',\n",
       " 'successor_label',\n",
       " 'successor',\n",
       " 'thumbnail_label',\n",
       " 'thumbnail',\n",
       " 'transmission',\n",
       " 'variantOf_label',\n",
       " 'variantOf',\n",
       " 'vehicle_label',\n",
       " 'vehicle',\n",
       " 'weight',\n",
       " 'wheelbase',\n",
       " 'width',\n",
       " 'point',\n",
       " '22-rdf-syntax-ns#type_label',\n",
       " '22-rdf-syntax-ns#type',\n",
       " 'wgs84_pos#lat',\n",
       " 'wgs84_pos#long',\n",
       " 'depiction_label',\n",
       " 'depiction',\n",
       " 'name']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(input_file, output_good, output_bad):\n",
    "\n",
    "    with open(input_file, \"r\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        header = reader.fieldnames\n",
    "\n",
    "        #COMPLETE THIS FUNCTION\n",
    "\n",
    "\n",
    "\n",
    "    # This is just an example on how you can use csv.DictWriter\n",
    "    # Remember that you have to output 2 files\n",
    "    with open(output_good, \"w\") as g:\n",
    "        writer = csv.DictWriter(g, delimiter=\",\", fieldnames= header)\n",
    "        writer.writeheader()\n",
    "        for row in YOURDATA:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'YOURDATA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4ea7bf8c07ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-4ea7bf8c07ba>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprocess_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINPUT_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUTPUT_GOOD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUTPUT_BAD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-7bdbc88af44e>\u001b[0m in \u001b[0;36mprocess_file\u001b[0;34m(input_file, output_good, output_bad)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfieldnames\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteheader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mYOURDATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'YOURDATA' is not defined"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    process_file(INPUT_FILE, OUTPUT_GOOD, OUTPUT_BAD)\n",
    "\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
